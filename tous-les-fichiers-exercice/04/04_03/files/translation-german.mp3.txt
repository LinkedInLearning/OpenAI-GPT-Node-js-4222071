Questions, writing poems, formulating e-mails. Millions of people can use the chatGPT language model. But how does this so-called generative artificial intelligence actually work? First of all, it needs a lot of human help. It has to be trained. chatGPT was created with hundreds of millions of texts. Including the complete Wikipedia. On the basis of these texts, the language AIs can explore the context of the language. They learn with what probability one word follows another. At the beginning of the training, the answers must be checked by humans. They exclude false or unwanted answers. So what happens when you ask a question in chatGPT? The input text is divided into many small units, so-called tokens. If a sentence is a puzzle, then a token is a piece of the puzzle. A token can be a short word, a short sentence, a short sentence, a sentence, a sentence, A token can be a short word, a syllable in a word, an abbreviation or a sentence. Then the model calculates the position of the tokens in the text and the context in which they are related. So the model can calculate the meaning of terms in the text. So the bank can mean something different depending on whether there is a park or money nearby. It also recognizes the meaning of the question. It identifies keywords in the text, recognizes instructions for work and ignores flasks. The creation of the answer works similarly. Based on the input and training data, the most likely answer is calculated and put together again like a puzzle. For each token, it is calculated which probability follows next. This creates the answer that the model considers most likely. You have to know that the model itself has no factual knowledge and cannot verify the correctness of the answer. So if a language model like ChatGPT answers a question correctly, then only because the correct answer is statistically the most likely. If there is little data available, it can happen that the calculated answer is wrong in content. This can still sound very convincing. That is why the answer of a language model does not replace its own research and should be checked independently. In summary, one can say that language AIs are only as good as their training data and the training process allow it. Their answers are not knowledge, but very good linguistic probability calculations. Nevertheless, they will change our lives as text generators in everyday work, chatbots or even humanoid robots.