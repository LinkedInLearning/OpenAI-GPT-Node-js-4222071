Fragen stellen, Gedichte schreiben, E-Mails formulieren – Millionen von Menschen lassen sich vom Sprachmodell Chat-GPT helfen. Aber wie funktioniert diese sogenannte generative künstliche Intelligenz eigentlich? Zunächst braucht sie viel menschliche Hilfe. Sie muss trainiert werden. Chat-GPT wurde mit hunderten Millionen von Texten aller Art gefüttert, inklusive der kompletten Wikipedia. Auf Basis dieser Texte können sich die Sprach-KIs Zusammenhänge der Sprache erschließen. Sie lernen, mit welcher Wahrscheinlichkeit ein Wort auf ein anderes folgt. Am Anfang des Trainings müssen die Antworten von Menschen überprüft werden. Sie schließen falsche oder unerwünschte Antworten aus. Aus diesem Feedback lernt das System wiederum und verbessert die Antworten laufend. Was passiert also, wenn man Chat-GPT eine Frage stellt? Der eingegebene Text wird in viele kleine Einheiten, sogenannte Tokens, unterteilt. Wenn ein Satz ein Puzzle ist, dann ist ein Token ein Puzzlestück. Ein Token kann dabei ein kurzes Wort sein, eine Silbe in einem Wort, eine Abkürzung oder ein Satzzeichen. Dann berechnet das Modell, auf welcher Position die Tokens im Text sind und in welchem Zusammenhang sie zueinander stehen. So kann das Modell die Bedeutung von Begriffen im Text berechnen, also dass Bank etwas anderes bedeuten kann, je nachdem, ob in der Nähe Park oder Geld vorkommt. Es erkennt daraus auch den Sinn der Frage. Es identifiziert Schlüsselwörter im Text, erkennt Arbeitsanweisungen und ignoriert Floskeln. Die Erstellung der Antwort funktioniert ähnlich. Auf Basis der Eingabe und der Trainingsdaten wird die wahrscheinlichste Antwort errechnet und wieder wie ein Puzzle zusammengesetzt. Für jedes Token wird berechnet, welches wahrscheinlich als nächstes folgt. So entsteht die Antwort, die das Modell für am wahrscheinlichsten passend hält. Dazu muss man wissen, das Modell selbst verfügt über kein Faktenwissen und kann die Richtigkeit der Antwort nicht überprüfen. Wenn also ein Sprachmodell wie ChatGPT auf eine Frage richtig antwortet, dann nur, weil die richtige Antwort statistisch gesehen die wahrscheinlichste ist. Stehen wenig Daten zur Verfügung, kann es vorkommen, dass die berechnete Antwort inhaltlich falsch ist. Das kann trotzdem sehr überzeugend klingen. Darum ersetzt die Antwort eines Sprachmodells keine eigene Recherche und sollte unabhängig überprüft werden. Zusammenfassend kann man sagen, Sprach-KIs sind nur so gut, wie ihre Trainingsdaten und der Trainingsprozess es zulassen. Ihre Antworten sind kein Wissen, sondern sehr gute sprachliche Wahrscheinlichkeitsrechnung. Trotzdem werden sie unser Leben verändern. Als Textgeneratoren im Arbeitsalltag, Chatbots oder sogar humanoide Roboter. Untertitel der Amara.org-Community